{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xy2119/Brain_MRI_Image_Segmentation/blob/main/notebooks/Covid19_NER_BioBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Biomedical Natural Language Processing | Named Entity Recognition with BioBERT\n",
        "# Submission to the 2021 Imperial College Data Science Challenge\n",
        "\n",
        "In the 2021 **[Data Science Institute](https://www.imperial.ac.uk/data-science/) Natural Language Processing Challenge**, a dataset was made available for text mining task, which is the [CORD-19](https://www.kaggle.com/datasets/allen-institute-for-ai/CORD-19-research-challenge) dataset from Kaggle. We're keen on looking into word representations and relational graphs that could serve as a medical and scientific knowledge repository.\n",
        "\n",
        "This notebook extracts biomedical entities from the Covid19 literatures (title, abstract, body...) by fine-tuning BioBERT.\n",
        "\n",
        "### **What is a Biomedical Entity?**\n",
        "Biomedical entity is a term that refers to anything related to the field of biomedicine. This can include things like proteins, genes, diseases, and medical treatments etc.\n",
        "\n",
        "### **Why Named Entity Recognition in the Biomedical Field**\n",
        "Named entity recognition (NER) is an important task used to extract information from biomedical articles.\n",
        "NER is the process to automatically recognize and classify the named entities. After extraction, they can be used in downstream tasks such as relation extraction, knowledge base construction, and knowledge discovery. \n",
        "\n",
        "### **BioBERT**\n",
        "BioBERT is model that is pre-trained on the biomedical datasets. In the pre-training, weights of the regular BERT model was taken and then pre-trained on the medical datasets like (PubMed abstracts and PMC). This domain-specific pre-trained model can be fine-tunned on smaller task-specific datasets. Literatures has proven that fine-tuning BIOBERT model outperformed the fine-tuned BERT model for the biomedical domain-specific NLP tasks.\n"
      ],
      "metadata": {
        "id": "ACeI22AyH27p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some information might be helpful before repreducing this notebook:\n",
        "\n",
        "\n",
        "* I track my training using `wandb`. `wandb` is a tool for tracking and visualising machine learning experiments in real time on [Weights & Biases](https://wandb.ai/site) platform. Create an account and experiment with the interactive dashboards! If you already have an account, that's fantastic! To monitor this experiment, launch the notebook and paste your API key from your profile.\n",
        "\n",
        "\n",
        "* I import CORD 19 NER Dataset from Google Drive, the dataset URL is available [here](https://drive.google.com/drive/folders/1Y4MUrrfT-Xuos83nOnq8ZWTMZmp9qADH?usp=sharing). Credit to Sushil Kumar [(profile)](https://www.linkedin.com/in/sushilksharma1/) for processing the dataset.\n",
        "\n",
        "\n",
        "Feel free to contact me at xy2119@ic.ac.uk"
      ],
      "metadata": {
        "id": "vdlPCvr4mK1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and Import Libraries"
      ],
      "metadata": {
        "id": "-JXsvnjRH27t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install tqdm\n",
        "!python -m spacy download en\n",
        "!pip install transformers\n",
        "!pip install pytorch-pretrained-bert"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-07-07T14:54:27.970444Z",
          "iopub.execute_input": "2022-07-07T14:54:27.971198Z",
          "iopub.status.idle": "2022-07-07T14:55:36.737804Z",
          "shell.execute_reply.started": "2022-07-07T14:54:27.971089Z",
          "shell.execute_reply": "2022-07-07T14:55:36.736732Z"
        },
        "trusted": true,
        "id": "7m9xx8BbH27u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import warnings\n",
        "import itertools\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import functools\n",
        "import itertools\n",
        "import operator\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict, OrderedDict\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.blank('en')\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_pretrained_bert\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "from pytorch_pretrained_bert import BertModel, BertTokenizer, BertConfig\n",
        "from seqeval.metrics import classification_report as classification_report_seqeval\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.exceptions import UndefinedMetricWarning"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:55:45.217642Z",
          "iopub.execute_input": "2022-07-07T14:55:45.21814Z",
          "iopub.status.idle": "2022-07-07T14:55:51.696115Z",
          "shell.execute_reply.started": "2022-07-07T14:55:45.218104Z",
          "shell.execute_reply": "2022-07-07T14:55:51.695205Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SNCmEHkH27y",
        "outputId": "91fb4e85-bf3c-4b04-c625-a688daa7ba7d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:55:51.69836Z",
          "iopub.execute_input": "2022-07-07T14:55:51.698647Z",
          "iopub.status.idle": "2022-07-07T14:55:51.93239Z",
          "shell.execute_reply.started": "2022-07-07T14:55:51.698607Z",
          "shell.execute_reply": "2022-07-07T14:55:51.931581Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRQWb3neH27z",
        "outputId": "747f40ab-3ef1-48e9-898e-8377c8d29516"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "warnings.warn = warn"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:55:51.933838Z",
          "iopub.execute_input": "2022-07-07T14:55:51.934677Z",
          "iopub.status.idle": "2022-07-07T14:55:51.94125Z",
          "shell.execute_reply.started": "2022-07-07T14:55:51.934636Z",
          "shell.execute_reply": "2022-07-07T14:55:51.94041Z"
        },
        "trusted": true,
        "id": "LOHB0s7IH270"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:55:51.943129Z",
          "iopub.execute_input": "2022-07-07T14:55:51.943753Z",
          "iopub.status.idle": "2022-07-07T14:55:59.740256Z",
          "shell.execute_reply.started": "2022-07-07T14:55:51.943717Z",
          "shell.execute_reply": "2022-07-07T14:55:59.739468Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UqMcp0KH270",
        "outputId": "bb684013-5643-4b3f-d28e-68fd4b7cafce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "print('GPU type:', torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:55:59.741676Z",
          "iopub.execute_input": "2022-07-07T14:55:59.742181Z",
          "iopub.status.idle": "2022-07-07T14:55:59.755805Z",
          "shell.execute_reply.started": "2022-07-07T14:55:59.742142Z",
          "shell.execute_reply": "2022-07-07T14:55:59.754944Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezv--ikoH270",
        "outputId": "f6261608-4275-413c-a95b-cbd37299d60c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "GPU type: A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb login\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLywiEK0Iaif",
        "outputId": "3479c46b-184f-450d-8312-4dbde720db7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxy2119\u001b[0m (\u001b[33mfancykid\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize W&B    \n",
        "wandb.init(project=\"covid19_knowledge_representation\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:55:36.740105Z",
          "iopub.execute_input": "2022-07-07T14:55:36.740375Z",
          "iopub.status.idle": "2022-07-07T14:55:45.215736Z",
          "shell.execute_reply.started": "2022-07-07T14:55:36.740335Z",
          "shell.execute_reply": "2022-07-07T14:55:45.214941Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "FGduri1YH27w",
        "outputId": "18d4bf59-2cb3-4515-e7b2-84da1d6f399e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221204_175041-fcnaanue</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/fancykid/covid19_knowledge_representation/runs/fcnaanue\" target=\"_blank\">upbeat-morning-7</a></strong> to <a href=\"https://wandb.ai/fancykid/covid19_knowledge_representation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/fancykid/covid19_knowledge_representation/runs/fcnaanue?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f5ad6055ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Pretrained BioBERT"
      ],
      "metadata": {
        "id": "uH6fwFee-ZMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/dmis-lab/biobert-v1.1"
      ],
      "metadata": {
        "id": "BtJlBI51Yo_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o /content/drive/MyDrive/COVID19_KG/ner_covid19_data.csv.zip -d ./"
      ],
      "metadata": {
        "id": "gCdDm6-uRHwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load CORD 19 NER Dataset\n",
        "Fullset of data is 63308700 in length. A subset is sampled here for this notebook"
      ],
      "metadata": {
        "id": "2Y-A37Nt_psB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/ner_covid19_data.csv')\n",
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhIbVLs5PMIM",
        "outputId": "72d04dd5-8cfb-42e8-8848-b70385cdd51f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63308700"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=df[:50000]\n",
        "data.fillna('0',inplace=True)\n",
        "data.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
        "drop_tags_less_than_10000=list(data['1'].value_counts()[data['1'].value_counts() < 10000].index)\n",
        "\n",
        "index__to_drop=[]\n",
        "for i in drop_tags_less_than_10000:\n",
        "    index__to_drop.extend(data[ data['1'] == i ].index)\n",
        "    \n",
        "data.drop(index__to_drop, inplace = True)\n",
        "\n",
        "data.rename(columns={\"0\": \"Word\", \"1\": \"Tag\",\"2\":\"Sentence #\"},inplace=True)\n",
        "data.drop(data.query('Tag == \"Other\"').sample(frac=.9).index, inplace = True)\n",
        "\n",
        "tag_values = data['Tag'].values\n",
        "vocab_len = len(tag_values)\n",
        "print('No. of entities:',vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnuIHjHYiijU",
        "outputId": "ed2efc3b-73c1-4a83-ec6b-39d1d15d4b05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of entities: 3827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GetSentence(object):\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "        self.n_sentences = 1\n",
        "        self.empty = False\n",
        "        agg_function = lambda s: [(w,t) for w,t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                        s[\"Tag\"].values.tolist())]\n",
        "        self.group = self.data.groupby('Sentence #').apply(agg_function)\n",
        "        self.sentence = [s for s in self.group]\n",
        "getter = GetSentence(data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:39.906141Z",
          "iopub.execute_input": "2022-07-07T14:56:39.906822Z",
          "iopub.status.idle": "2022-07-07T14:56:39.9141Z",
          "shell.execute_reply.started": "2022-07-07T14:56:39.906782Z",
          "shell.execute_reply": "2022-07-07T14:56:39.91323Z"
        },
        "trusted": true,
        "id": "qH4_1gL5H272"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag1 = [[word[1] for word in sentence] for sentence in getter.sentence]\n",
        "sentences1 = [[word[0] for word in sentence] for sentence in getter.sentence]\n",
        "\n",
        "sentences = sentences1\n",
        "tags = tag1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:40.642475Z",
          "iopub.execute_input": "2022-07-07T14:56:40.642715Z",
          "iopub.status.idle": "2022-07-07T14:56:40.694417Z",
          "shell.execute_reply.started": "2022-07-07T14:56:40.642682Z",
          "shell.execute_reply": "2022-07-07T14:56:40.693716Z"
        },
        "trusted": true,
        "id": "lgO0ly0zH273"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 100\n",
        "BATCH_SIZE = 16\n",
        "tokenizer = BertTokenizer(vocab_file='/content/biobert_v1.1_pubmed/vocab.txt', do_lower_case=False)\n",
        "\n",
        "def tok_with_labels(sent, text_labels):\n",
        "    tok_sent = []\n",
        "    labels = []\n",
        "    for word, label in zip(sent, text_labels):\n",
        "        tok_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tok_word)\n",
        "\n",
        "        tok_sent.extend(tok_word)\n",
        "        labels.extend([label] * n_subwords)\n",
        "    return tok_sent, labels\n",
        "\n",
        "%time\n",
        "tok_texts_and_labels = [tok_with_labels(sent, labs) for sent, labs in zip(sentences, tags)]\n",
        "tok_texts = [tok_label_pair[0] for tok_label_pair in tok_texts_and_labels]\n",
        "labels = [tok_label_pair[1] for tok_label_pair in tok_texts_and_labels]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:40.695741Z",
          "iopub.execute_input": "2022-07-07T14:56:40.696003Z",
          "iopub.status.idle": "2022-07-07T14:56:40.703373Z",
          "shell.execute_reply.started": "2022-07-07T14:56:40.695968Z",
          "shell.execute_reply": "2022-07-07T14:56:40.70169Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtcR66hyH273",
        "outputId": "b4832716-d198-479f-db39-c06ec8d50b3d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 6.2 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for char in tok_texts:\n",
        "    print('Example of tokenized wordpiece:\\n', char)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmuLFbd4jxPA",
        "outputId": "57a49738-b4af-4259-ac1a-428eeffe4ee5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example of tokenized wordpiece:\n",
            " ['mechanisms', 'analysis', '[', '3', ',', 'possible', 'there', 'many', 'have', 'strong', 'studies', 'share']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tok_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:47.039159Z",
          "iopub.execute_input": "2022-07-07T14:56:47.039423Z",
          "iopub.status.idle": "2022-07-07T14:56:47.046605Z",
          "shell.execute_reply.started": "2022-07-07T14:56:47.039388Z",
          "shell.execute_reply": "2022-07-07T14:56:47.045827Z"
        },
        "trusted": true,
        "id": "jaimYvC0H273"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_values = list(set(itertools.chain.from_iterable(tags)))\n",
        "tag_values.append(\"PAD\")\n",
        "\n",
        "tag2idx = {t: i for i,t in enumerate(tag_values)}\n",
        "print('No. of tag indices:', tag2idx)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:47.222142Z",
          "iopub.execute_input": "2022-07-07T14:56:47.222625Z",
          "iopub.status.idle": "2022-07-07T14:56:47.237172Z",
          "shell.execute_reply.started": "2022-07-07T14:56:47.222588Z",
          "shell.execute_reply": "2022-07-07T14:56:47.236467Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YDA9sVRH274",
        "outputId": "929ae705-3f38-46e7-9951-9c41418284a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of tag indices: {'Other': 0, 'PAD': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:47.249626Z",
          "iopub.execute_input": "2022-07-07T14:56:47.250036Z",
          "iopub.status.idle": "2022-07-07T14:56:47.379581Z",
          "shell.execute_reply.started": "2022-07-07T14:56:47.250001Z",
          "shell.execute_reply": "2022-07-07T14:56:47.378869Z"
        },
        "trusted": true,
        "id": "f2L_fy9CH274"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save you ids and tags in case the full dataset run out of you RAM and crashed\n",
        "# pd.DataFrame(input_ids).to_csv(r'input_ids.txt', header=None, index=None, sep=' ', mode='a')\n",
        "# pd.DataFrame(tags).to_csv(r'tags.txt', header=None, index=None, sep=' ', mode='a')"
      ],
      "metadata": {
        "id": "H_vNq7DIk7Vy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:47.380962Z",
          "iopub.execute_input": "2022-07-07T14:56:47.381206Z",
          "iopub.status.idle": "2022-07-07T14:56:49.688237Z",
          "shell.execute_reply.started": "2022-07-07T14:56:47.381169Z",
          "shell.execute_reply": "2022-07-07T14:56:49.687498Z"
        },
        "trusted": true,
        "id": "9__iPm08H274"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n",
        "                                                            random_state=2022, test_size=0.18)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2022, test_size=0.18)\n",
        "\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:49.689678Z",
          "iopub.execute_input": "2022-07-07T14:56:49.689967Z",
          "iopub.status.idle": "2022-07-07T14:56:49.790838Z",
          "shell.execute_reply.started": "2022-07-07T14:56:49.689927Z",
          "shell.execute_reply": "2022-07-07T14:56:49.790059Z"
        },
        "trusted": true,
        "id": "WAkDydclH275"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:49.792091Z",
          "iopub.execute_input": "2022-07-07T14:56:49.792377Z",
          "iopub.status.idle": "2022-07-07T14:56:49.79982Z",
          "shell.execute_reply.started": "2022-07-07T14:56:49.792332Z",
          "shell.execute_reply": "2022-07-07T14:56:49.798998Z"
        },
        "trusted": true,
        "id": "claLxbK8H275"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig.from_json_file('/content/biobert_v1.1_pubmed/config.json')\n",
        "tmp_d = torch.load('/content/biobert_v1.1_pubmed/pytorch_model.bin', map_location=device)\n",
        "state_dict = OrderedDict()\n",
        "\n",
        "for i in list(tmp_d.keys())[:199]:\n",
        "    x = i\n",
        "    if i.find('bert') > -1:\n",
        "        x = '.'.join(i.split('.')[1:])\n",
        "    state_dict[x] = tmp_d[i]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:49.800968Z",
          "iopub.execute_input": "2022-07-07T14:56:49.801352Z",
          "iopub.status.idle": "2022-07-07T14:56:50.082403Z",
          "shell.execute_reply.started": "2022-07-07T14:56:49.801315Z",
          "shell.execute_reply": "2022-07-07T14:56:50.081646Z"
        },
        "trusted": true,
        "id": "KOKwGxlJH275"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BioBertNER(nn.Module):\n",
        "    def __init__(self, vocab_len, config, state_dict):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel(config)\n",
        "        self.bert.load_state_dict(state_dict, strict=False)\n",
        "        self.dropout = nn.Dropout(p=0.10)\n",
        "        self.output = nn.Linear(self.bert.config.hidden_size, vocab_len)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        encoded_layer, _ = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        encl = encoded_layer[-1]\n",
        "        out = self.dropout(encl)\n",
        "        out = self.output(out)\n",
        "        return out, out.argmax(-1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:50.083726Z",
          "iopub.execute_input": "2022-07-07T14:56:50.083987Z",
          "iopub.status.idle": "2022-07-07T14:56:50.093166Z",
          "shell.execute_reply.started": "2022-07-07T14:56:50.083954Z",
          "shell.execute_reply": "2022-07-07T14:56:50.09235Z"
        },
        "trusted": true,
        "id": "BOE7Bqn7H275"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture With Pretrained Weights\n"
      ],
      "metadata": {
        "id": "g1kYoxcZH276"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BioBertNER(vocab_len,config,state_dict)\n",
        "model.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:50.09874Z",
          "iopub.execute_input": "2022-07-07T14:56:50.098966Z",
          "iopub.status.idle": "2022-07-07T14:56:53.261449Z",
          "shell.execute_reply.started": "2022-07-07T14:56:50.098938Z",
          "shell.execute_reply": "2022-07-07T14:56:53.260681Z"
        },
        "trusted": true,
        "id": "cvdmvBIOH276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30b6254-913e-4503-ff4e-eaa8f62a9096"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BioBertNER(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (output): Linear(in_features=768, out_features=3827, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=5e-5,\n",
        "    eps=1e-8\n",
        ")\n",
        "epochs = 20\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:53.262894Z",
          "iopub.execute_input": "2022-07-07T14:56:53.263314Z",
          "iopub.status.idle": "2022-07-07T14:56:53.276801Z",
          "shell.execute_reply.started": "2022-07-07T14:56:53.263273Z",
          "shell.execute_reply": "2022-07-07T14:56:53.276052Z"
        },
        "trusted": true,
        "id": "xusDiI7rH276"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.config.update = {\n",
        "  \"learning_rate\": 5e-5,\n",
        "  \"epochs\": 20,\n",
        "  \"batch_size\": 16,\n",
        "  \"eps\": 1e-8,\n",
        "  \"max_grad_norm\": 1.0\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:53.278224Z",
          "iopub.execute_input": "2022-07-07T14:56:53.27849Z",
          "iopub.status.idle": "2022-07-07T14:56:53.289006Z",
          "shell.execute_reply.started": "2022-07-07T14:56:53.278453Z",
          "shell.execute_reply": "2022-07-07T14:56:53.28817Z"
        },
        "trusted": true,
        "id": "PegPVvACH276"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Evaluation (tracked by wandb.)"
      ],
      "metadata": {
        "id": "8HNxLR4HH276"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    for step,batch in tqdm(enumerate(data_loader)):\n",
        "        batch = tuple(t.to(device).long() for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        outputs,y_hat = model(b_input_ids,b_input_mask)\n",
        "        \n",
        "        _,preds = torch.max(outputs,dim=2)\n",
        "        outputs = outputs.view(-1,outputs.shape[-1])\n",
        "        b_labels_shaped = b_labels.view(-1)\n",
        "        loss = loss_fn(outputs,b_labels_shaped)\n",
        "        correct_predictions += torch.sum(preds == b_labels)\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    return correct_predictions.double()/len(data_loader) , np.mean(losses)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:53.29035Z",
          "iopub.execute_input": "2022-07-07T14:56:53.290813Z",
          "iopub.status.idle": "2022-07-07T14:56:53.309195Z",
          "shell.execute_reply.started": "2022-07-07T14:56:53.290777Z",
          "shell.execute_reply": "2022-07-07T14:56:53.308254Z"
        },
        "trusted": true,
        "id": "_3pI4tMXH276"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_eval(model,data_loader,loss_fn,device):\n",
        "    model = model.eval()\n",
        "    \n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for step, batch in enumerate(data_loader):\n",
        "            batch = tuple(t.to(device).long() for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "            outputs,y_hat = model(b_input_ids,b_input_mask)\n",
        "        \n",
        "            _,preds = torch.max(outputs,dim=2)\n",
        "            outputs = outputs.view(-1,outputs.shape[-1])\n",
        "            b_labels_shaped = b_labels.view(-1)\n",
        "            loss = loss_fn(outputs,b_labels_shaped)\n",
        "            correct_predictions += torch.sum(preds == b_labels)\n",
        "            losses.append(loss.item())\n",
        "        \n",
        "    \n",
        "    return correct_predictions.double()/len(data_loader) , np.mean(losses)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:53.310466Z",
          "iopub.execute_input": "2022-07-07T14:56:53.310714Z",
          "iopub.status.idle": "2022-07-07T14:56:53.323176Z",
          "shell.execute_reply.started": "2022-07-07T14:56:53.310678Z",
          "shell.execute_reply": "2022-07-07T14:56:53.322361Z"
        },
        "trusted": true,
        "id": "moQwk3DPH277"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "normalizer = BATCH_SIZE*MAX_LEN\n",
        "loss_values = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    total_loss = 0\n",
        "    print(f'======== Epoch {epoch+1}/{epochs} ========')\n",
        "    train_acc,train_loss = train_epoch(model,train_dataloader,loss_fn,optimizer,device,scheduler)\n",
        "    train_acc = train_acc/normalizer\n",
        "    print(f'Train Loss: {train_loss} Train Accuracy: {train_acc}')\n",
        "    total_loss += train_loss.item()\n",
        "    \n",
        "    avg_train_loss = total_loss / len(train_dataloader)  \n",
        "    loss_values.append(avg_train_loss)\n",
        "    \n",
        "    val_acc,val_loss = model_eval(model,valid_dataloader,loss_fn,device)\n",
        "    val_acc = val_acc/normalizer\n",
        "    print(f'Val Loss: {val_loss} Val Accuracy: {val_acc}')\n",
        "    \n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    \n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    wandb.log({\"train_acc\":train_acc, \"train_loss\":train_loss,\"val_acc\":val_acc,\"val_loss\":val_loss,})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T14:56:53.325973Z",
          "iopub.execute_input": "2022-07-07T14:56:53.326811Z",
          "iopub.status.idle": "2022-07-07T16:13:22.552415Z",
          "shell.execute_reply.started": "2022-07-07T14:56:53.326753Z",
          "shell.execute_reply": "2022-07-07T16:13:22.551659Z"
        },
        "trusted": true,
        "id": "AU0zYq4CH277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b5a06c-8a88-4839-e975-9a6dbf22a11e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:02,  8.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.325054889633542 Train Accuracy: 0.8092857142857143\n",
            "Val Loss: 0.5990190267562866 Val Accuracy: 0.809\n",
            "======== Epoch 2/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5147379033622288 Train Accuracy: 0.8751488095238095\n",
            "Val Loss: 0.07912601679563522 Val Accuracy: 0.9125\n",
            "======== Epoch 3/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.05251270293125084 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.012264871038496494 Val Accuracy: 0.9125\n",
            "======== Epoch 4/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.01719637569927034 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.00786614753305912 Val Accuracy: 0.9125\n",
            "======== Epoch 5/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.017481766641139984 Train Accuracy: 0.9748809523809523\n",
            "Val Loss: 0.006592871248722076 Val Accuracy: 0.9125\n",
            "======== Epoch 6/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.010358952030184724 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.005189283471554518 Val Accuracy: 0.9125\n",
            "======== Epoch 7/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.008507519649962584 Train Accuracy: 0.9761607142857142\n",
            "Val Loss: 0.004521099757403136 Val Accuracy: 0.9125\n",
            "======== Epoch 8/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.007604492251716909 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.003950533457100391 Val Accuracy: 0.9125\n",
            "======== Epoch 9/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.006524642020286549 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.003494596667587757 Val Accuracy: 0.9125\n",
            "======== Epoch 10/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.005872780479313363 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.0031978955492377283 Val Accuracy: 0.9125\n",
            "======== Epoch 11/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0053687684371003085 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.0029352221637964247 Val Accuracy: 0.9125\n",
            "======== Epoch 12/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0049535226342933515 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.0027305235620588065 Val Accuracy: 0.9125\n",
            "======== Epoch 13/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.004639158069732643 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.0025704404804855587 Val Accuracy: 0.9125\n",
            "======== Epoch 14/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.004396003449246997 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.002443480212241411 Val Accuracy: 0.9125\n",
            "======== Epoch 15/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.004189393394404934 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.002335597760975361 Val Accuracy: 0.9125\n",
            "======== Epoch 16/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.004012308826315261 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.0022550362162292005 Val Accuracy: 0.9125\n",
            "======== Epoch 17/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.003898823722487404 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.0021939555648714305 Val Accuracy: 0.9125\n",
            "======== Epoch 18/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0038106578757010753 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.002150867972522974 Val Accuracy: 0.9125\n",
            "======== Epoch 19/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.003743567836603948 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.0021253110375255347 Val Accuracy: 0.9125\n",
            "======== Epoch 20/20 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 11.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0037006320365305457 Train Accuracy: 0.9761904761904763\n",
            "Val Loss: 0.0021161667071282865 Val Accuracy: 0.9125\n",
            "CPU times: user 38.8 s, sys: 2.02 s, total: 40.8 s\n",
            "Wall time: 40.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "plt.plot(loss_values, 'b-o')\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:13:22.553615Z",
          "iopub.execute_input": "2022-07-07T16:13:22.553872Z",
          "iopub.status.idle": "2022-07-07T16:13:22.828291Z",
          "shell.execute_reply.started": "2022-07-07T16:13:22.553836Z",
          "shell.execute_reply": "2022-07-07T16:13:22.82759Z"
        },
        "trusted": true,
        "id": "VMuFlf1RH277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "eb8579a3-3de4-45ca-d2e9-37b0edff9825"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "t98hyGtWH277"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"IPakistan has vaccinated over 122 million people. The two vaccines in widespread use are inactivated (BBIBP-CorV & Sinovac) and mRNA forms (BNT162b2 & mRNA-1273). The primary aim of this study was to compare these two forms of vaccines against unvaccinated individuals collectively and then to see which one is more efficacious. Case–control study design was used to compare the efficacy of inactivated and mRNA vaccines against symptomatic infection, hospitalisations and mortality due to Severe Acute Respiratory Syndrome Coronavirus 2 between vaccinated and unvaccinated individuals. We derived recovery time from illness for both vaccines. Furthermore, we also compared the vaccines against similar parameters (symptomatic disease, hospitalisations and mortality). We calculated crude odds ratios for each dependent variable. p value of 0.05 or below was considered significant.\n",
        "\"\"\"\n",
        "text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^.0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:13:22.829488Z",
          "iopub.execute_input": "2022-07-07T16:13:22.831013Z",
          "iopub.status.idle": "2022-07-07T16:13:22.838882Z",
          "shell.execute_reply.started": "2022-07-07T16:13:22.830972Z",
          "shell.execute_reply": "2022-07-07T16:13:22.838022Z"
        },
        "trusted": true,
        "id": "f2dkTGq_H278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464bf7f4-cd6c-49b9-e97a-ba6f92b47cf5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IPakistan has vaccinated over 122million people. The two vaccines in widespread use are inactivated BBIBPCorV  Sinovac and mRNA forms BNT162b2  mRNA1273. The primary aim of this study was to compare these two forms of vaccines against unvaccinated individuals collectively and then to see which one is more efficacious. Casecontrol study design was used to compare the efficacy of inactivated and mRNA vaccines against symptomatic infection hospitalisations and mortality due to Severe Acute Respiratory Syndrome Coronavirus 2 between vaccinated and unvaccinated individuals. We derived recovery time from illness for both vaccines. Furthermore we also compared the vaccines against similar parameters symptomatic disease hospitalisations and mortality. We calculated crude odds ratios for each dependent variable. p value of 0.05 or below was considered significant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_text1=[]\n",
        "for i in sent_text:\n",
        "    sent_text1.append(re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", i))\n",
        "\n",
        "tokenized_text = []\n",
        "for sentence in sent_text1:\n",
        "    tokenized_text.append(nltk.word_tokenize(sentence))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:13:23.060025Z",
          "iopub.execute_input": "2022-07-07T16:13:23.06044Z",
          "iopub.status.idle": "2022-07-07T16:13:23.076396Z",
          "shell.execute_reply.started": "2022-07-07T16:13:23.060402Z",
          "shell.execute_reply": "2022-07-07T16:13:23.075325Z"
        },
        "trusted": true,
        "id": "cLzqNg9uH278"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_preserve(sentence):\n",
        "    tokenized_sentence = []\n",
        "    for word in sentence:\n",
        "        tokenized_word = tokenizer.tokenize(word)   \n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "    return tokenized_sentence\n",
        "\n",
        "tok_texts = [tokenize_and_preserve(sent) for sent in tokenized_text]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(txt) for txt in tok_texts]\n",
        "input_attentions = [[1]*len(in_id) for in_id in input_ids]\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids[1])\n",
        "new_tokens, new_labels = [], []\n",
        "for token in tokens:\n",
        "    if token.startswith(\"##\"):\n",
        "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "    else:\n",
        "        new_tokens.append(token)"
      ],
      "metadata": {
        "id": "cDc_-kmQbqB2"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_sentences = []\n",
        "pred_labels = []\n",
        "for x,y in zip(input_ids,input_attentions):\n",
        "    x = torch.tensor(x).cuda()\n",
        "    y = torch.tensor(y).cuda()\n",
        "    x = x.view(-1,x.size()[-1])\n",
        "    y = y.view(-1,y.size()[-1])\n",
        "    with torch.no_grad():\n",
        "        _,y_hat = model(x,y)\n",
        "    label_indices = y_hat.to('cpu').numpy()\n",
        "    \n",
        "    tokens = tokenizer.convert_ids_to_tokens(x.to('cpu').numpy()[0])\n",
        "    new_tokens, new_labels = [], []\n",
        "    for token, label_idx in zip(tokens, label_indices[0]):\n",
        "        if token.startswith(\"##\"):\n",
        "            new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "        else:\n",
        "            new_labels.append(tag_values[label_idx])\n",
        "            new_tokens.append(token)\n",
        "    actual_sentences.append(new_tokens)\n",
        "    pred_labels.append(new_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:13:23.184642Z",
          "iopub.execute_input": "2022-07-07T16:13:23.185354Z",
          "iopub.status.idle": "2022-07-07T16:13:23.412069Z",
          "shell.execute_reply.started": "2022-07-07T16:13:23.185291Z",
          "shell.execute_reply": "2022-07-07T16:13:23.411277Z"
        },
        "trusted": true,
        "id": "a4BmQNSJH279"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent=[]\n",
        "tags=[]\n",
        "\n",
        "for token, label in zip(actual_sentences, pred_labels):\n",
        "    for t,l in zip(token,label):\n",
        "        sent.append(t)\n",
        "        tags.append(l)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:13:23.413152Z",
          "iopub.execute_input": "2022-07-07T16:13:23.413526Z",
          "iopub.status.idle": "2022-07-07T16:13:23.423195Z",
          "shell.execute_reply.started": "2022-07-07T16:13:23.413491Z",
          "shell.execute_reply": "2022-07-07T16:13:23.421558Z"
        },
        "trusted": true,
        "id": "T1TXbn0tH279"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst=[]\n",
        "total_words=[]\n",
        "temp=0\n",
        "test_sentence=' '.join(sent)\n",
        "for key,i in enumerate(sent):\n",
        "    if i not in total_words:\n",
        "        re_string = r\"\\b({})\\b\".format(i)\n",
        "        start=re.search(re_string, test_sentence).start()\n",
        "        end=re.search(re_string, test_sentence).end()\n",
        "        dict1={}\n",
        "        dict1[\"start\"]=start+temp\n",
        "        dict1[\"end\"]=end\n",
        "        dict1[\"label\"]=tags[key]\n",
        "        dict1[\"Word\"]=i\n",
        "        total_words.append(i)\n",
        "\n",
        "        lst.append(dict1)\n",
        "        \n",
        "    else:\n",
        "        start=start+len(sent[key-1])\n",
        "        end=end+len(i)+1\n",
        "\n",
        "        dict1={}\n",
        "        dict1[\"start\"]=start\n",
        "        dict1[\"end\"]=end\n",
        "        dict1[\"label\"]=tags[key]+'2'\n",
        "        dict1[\"Word\"]=i\n",
        "        total_words.append(i)\n",
        "\n",
        "        lst.append(dict1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:13:23.424304Z",
          "iopub.execute_input": "2022-07-07T16:13:23.42459Z",
          "iopub.status.idle": "2022-07-07T16:13:23.475453Z",
          "shell.execute_reply.started": "2022-07-07T16:13:23.424554Z",
          "shell.execute_reply": "2022-07-07T16:13:23.474812Z"
        },
        "trusted": true,
        "id": "BoJNtF3kH279"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex = [{\"text\": test_sentence,\n",
        "       \"ents\": lst,\n",
        "       \"title\": None}]\n",
        "cols = {'B-CARDINAL': '#dad1f6','B-CHEMICAL': '#f9d5de','B-DISEASE_OR_SYNDROME': '#adcfad','B-GENE_OR_GENOME': '#fbbf9a',\\\n",
        "        'I-CHEMICAL': '#bdf2fa','I-GENE_OR_GENOME': '#eea69e','Other': \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
        "options = {\"colors\": cols,}\n",
        "\n",
        "html = displacy.render(ex, style=\"ent\",options=options, manual=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:13:23.479233Z",
          "iopub.execute_input": "2022-07-07T16:13:23.481118Z",
          "iopub.status.idle": "2022-07-07T16:13:23.510492Z",
          "shell.execute_reply.started": "2022-07-07T16:13:23.48108Z",
          "shell.execute_reply": "2022-07-07T16:13:23.509881Z"
        },
        "trusted": true,
        "id": "lnX9WsuFH279"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save = 'BioBERT_NER.pt'\n",
        "path = F\"{model_save}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:13:23.51131Z",
          "iopub.execute_input": "2022-07-07T16:13:23.511524Z",
          "iopub.status.idle": "2022-07-07T16:13:26.057439Z",
          "shell.execute_reply.started": "2022-07-07T16:13:23.511494Z",
          "shell.execute_reply": "2022-07-07T16:13:26.056689Z"
        },
        "trusted": true,
        "id": "W_YqWHv9H27-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report(model,data_loader,device):\n",
        "    model = model.eval()\n",
        "    \n",
        "    all_pred=[]\n",
        "    true_label=[]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for step, batch in enumerate(data_loader):\n",
        "            batch = tuple(t.to(device).long() for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "            outputs,y_hat = model(b_input_ids,b_input_mask)\n",
        "        \n",
        "            _,preds = torch.max(outputs,dim=2)\n",
        "            \n",
        "            all_pred.extend(preds.tolist())\n",
        "            true_label.extend(b_labels.tolist())\n",
        "        \n",
        "    return all_pred,true_label\n",
        "\n",
        "def functools_reduce(a):\n",
        "    return functools.reduce(operator.concat, a)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:13:26.058568Z",
          "iopub.execute_input": "2022-07-07T16:13:26.059077Z",
          "iopub.status.idle": "2022-07-07T16:13:26.067245Z",
          "shell.execute_reply.started": "2022-07-07T16:13:26.059037Z",
          "shell.execute_reply": "2022-07-07T16:13:26.066518Z"
        },
        "trusted": true,
        "id": "KAJxBUR2H27-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pred,true_label= report(model,valid_dataloader,device)\n",
        "\n",
        "all_pred=functools_reduce(all_pred)\n",
        "true_label=functools_reduce(true_label)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:17:29.132486Z",
          "iopub.execute_input": "2022-07-07T16:17:29.132748Z",
          "iopub.status.idle": "2022-07-07T16:17:43.979004Z",
          "shell.execute_reply.started": "2022-07-07T16:17:29.132719Z",
          "shell.execute_reply": "2022-07-07T16:17:43.97822Z"
        },
        "trusted": true,
        "id": "fj6QtEXzH27-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2tag = {v: k for k, v in tag2idx.items()}\n",
        "all_pred=[*map(idx2tag.get, all_pred)]\n",
        "true_label=[*map(idx2tag.get, true_label)]\n",
        "print(classification_report(true_label, all_pred))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-07T16:17:53.481609Z",
          "iopub.execute_input": "2022-07-07T16:17:53.482004Z",
          "iopub.status.idle": "2022-07-07T16:17:57.137801Z",
          "shell.execute_reply.started": "2022-07-07T16:17:53.48197Z",
          "shell.execute_reply": "2022-07-07T16:17:57.137026Z"
        },
        "trusted": true,
        "id": "UwWiUAmUH27-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3df8fe-8eb9-455e-e61e-2a9372eb741e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Other       1.00      1.00      1.00       828\n",
            "         PAD       1.00      1.00      1.00      6472\n",
            "\n",
            "    accuracy                           1.00      7300\n",
            "   macro avg       1.00      1.00      1.00      7300\n",
            "weighted avg       1.00      1.00      1.00      7300\n",
            "\n"
          ]
        }
      ]
    }
  ]
}